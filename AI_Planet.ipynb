{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1jkPcBi/4cfUqnsPqIKl4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshu-coding/AiPlanet/blob/main/AI_Planet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers beautifulsoup4 requests cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0n6hVqozKq",
        "outputId": "d05afb51-4f58-4954-afd0-1b7f3853ed97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.11.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.11.3-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.7/248.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.11.3 fastavro-1.9.7 httpx-sse-0.4.0 parameterized-0.9.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sESaIVaPsXcO",
        "outputId": "7c983863-c140-49e5-eaa4-71fbdcf8b16f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f_XdCeFtuUY",
        "outputId": "d7279168-b27a-46f2-8e9d-ab86b7475695"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle  # Create the .kaggle directory if it doesn't exist.\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/  # Copy kaggle.json from the specified path in Google Drive to the .kaggle directory.\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set permissions to make the file secure."
      ],
      "metadata": {
        "id": "HhFZ_rrZO0ST"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO8RNqD-o6P-",
        "outputId": "97c66574-af66-44da-cc62-de61e404fc74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JDJ3i3GBmxte"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "from bs4 import BeautifulSoup\n",
        "import cohere\n",
        "from dotenv import load_dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Access your keys\n",
        "HUGGINGFACE_API_KEY = os.getenv('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')\n",
        "KAGGLE_API_KEY = os.getenv('196b544d3b74808434b5891d22969c36')"
      ],
      "metadata": {
        "id": "fMUrsP_inlbr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co = cohere.Client('GOKvZziDoZ32Jhi3pRLmItp8Pk3hKk6mcZAK6529')"
      ],
      "metadata": {
        "id": "FwjiSxizqDPo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ResearchAgent:\n",
        "    def research_industry(self, industry):\n",
        "        search_query = industry.replace(' ', '+') + '+AI+use+cases'\n",
        "        url = f\"https://www.google.com/search?q={search_query}\"\n",
        "\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            snippets = [item.text for item in soup.find_all('span')]\n",
        "            return snippets[:5]  # Return top 5 snippets for brevity\n",
        "        else:\n",
        "            return [\"Failed to fetch data from the web.\"]"
      ],
      "metadata": {
        "id": "uYz0WHNLpsaG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UseCaseGenerationAgent:\n",
        "    def generate_use_cases(self, industry_analysis):\n",
        "        analysis_text = \" \".join(industry_analysis)\n",
        "        response = co.generate(\n",
        "            model='command-xlarge',\n",
        "            prompt=f\"Based on the industry analysis: {analysis_text}, suggest potential AI use cases for this industry.\",\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response.generations[0].text.strip().split('\\n')\n"
      ],
      "metadata": {
        "id": "3TtyS1D6qr_h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResourceCollectorAgent:\n",
        "\n",
        "    def collect_huggingface_datasets(self, query):\n",
        "        headers = {\"Authorization\": f\"Bearer {HUGGINGFACE_API_KEY}\"}\n",
        "        url = f\"https://huggingface.co/api/datasets?search={query}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            datasets = response.json()[:5]  # Get top 5 results\n",
        "            return [f\"Hugging Face Dataset for Ai usecase in {query}: [Link](https://huggingface.co/datasets/{dataset['id']})\" for dataset in datasets]\n",
        "        else:\n",
        "            return [\"Failed to fetch Hugging Face data.\"]\n",
        "\n",
        "    def collect_kaggle_datasets(self, query):\n",
        "        try:\n",
        "            # Execute the Kaggle API command to search datasets\n",
        "            result = subprocess.run(['kaggle', 'datasets', 'list', '--search', query, '--csv'],\n",
        "                                    capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                lines = result.stdout.split('\\n')\n",
        "                dataset_links = []\n",
        "                for line in lines[1:6]:  # Get top 5 dataset results\n",
        "                    parts = line.split(',')\n",
        "                    if len(parts) > 1 and parts[0].strip():\n",
        "                        dataset_links.append(f\"Kaggle Dataset for Ai usecase in {query}: [Link](https://www.kaggle.com/{parts[0].strip()})\")\n",
        "                return dataset_links\n",
        "            else:\n",
        "                return [\"Kaggle API request failed.\"]\n",
        "        except Exception as e:\n",
        "            return [f\"Error: {str(e)}\"]\n",
        "\n",
        "    def collect_all_resources(self, industry):\n",
        "        huggingface_links = self.collect_huggingface_datasets(industry)\n",
        "        kaggle_links = self.collect_kaggle_datasets(industry)\n",
        "        return huggingface_links + kaggle_links"
      ],
      "metadata": {
        "id": "LPRqK8qqrNzV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ghMXP0E1Xbe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main workflow integration\n",
        "\n",
        "def main_workflow(industry):\n",
        "    # Step 1: Research Industry\n",
        "    research_agent = ResearchAgent()\n",
        "    industry_analysis = research_agent.research_industry(industry)\n",
        "\n",
        "    # Step 2: Generate Use Cases\n",
        "    use_case_agent = UseCaseGenerationAgent()\n",
        "    use_cases = use_case_agent.generate_use_cases(industry_analysis)\n",
        "\n",
        "    # Step 3: Collect Industry-Specific Datasets\n",
        "    resource_agent = ResourceCollectorAgent()\n",
        "    datasets = resource_agent.collect_all_resources(industry)\n",
        "\n",
        "    return use_cases, datasets\n",
        "\n",
        "# Example industry input\n",
        "industry = \"Steel\"\n",
        "use_cases, datasets = main_workflow(industry)\n",
        "\n",
        "# Display the use cases\n",
        "print(\"Use Cases:\")\n",
        "for use_case in use_cases:\n",
        "    print(use_case)\n",
        "\n",
        "# Display the industry-specific dataset links\n",
        "print(\"\\nIndustry-Specific Dataset Links:\")\n",
        "for dataset in datasets:\n",
        "    print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qQpMh3vrTFZ",
        "outputId": "906c6b8d-7e2e-46f7-c71f-938e99bcee51"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use Cases:\n",
            "Here are some potential AI use cases for the steel industry:\n",
            "\n",
            "1. Supply Chain Optimization: AI can analyze data from procurement, production, and logistics to optimize steel supply chain processes. It can predict demand, identify efficiencies, and improve resource allocation.\n",
            "\n",
            "2. Enhanced Quality Control: AI cameras and sensors can monitor production processes in real-time. Machine Learning can help identify irregularities, ensure product quality, and maintain health and safety standards.\n",
            "\n",
            "3. Predictive Maintenance: Using historical maintenance data and sensor information, AI can predict equipment failures, helping to avoid disruptions, expedite repairs, and reduce downtime. This is particularly crucial for expensive assets like blast furnaces.\n",
            "\n",
            "4. Energy Efficiency: AI can analyze energy consumption patterns and processes in steel production. It can identify areas for optimization, recommend energy-saving practices, and potentially reduce the industry's environmental impact.\n",
            "\n",
            "5. Demand and Production Forecasting: Leveraging historical data, market trends, and external factors, AI can improve demand forecasting, allowing steel companies to adjust production levels and minimize inventory costs.\n",
            "\n",
            "6. Autonomous Processes: AI can automate specific tasks, such as controlling autonomous vehicles in steelplants, managing logistics, and optimizing the transport of raw materials or finished products. \n",
            "\n",
            "7. Health and Safety Insights: Analyzing safety data and monitoring practices, AI can potentially identify hazards, provide safety recommendations, and help improve the well-being of steel industry employees. \n",
            "\n",
            "These are just a few examples of\n",
            "\n",
            "Industry-Specific Dataset Links:\n",
            "Hugging Face Dataset for Ai usecase in Steel: [Link](https://huggingface.co/datasets/mstz/steel_plates)\n",
            "Hugging Face Dataset for Ai usecase in Steel: [Link](https://huggingface.co/datasets/steelozazala/Test)\n",
            "Hugging Face Dataset for Ai usecase in Steel: [Link](https://huggingface.co/datasets/open-llm-leaderboard-old/details_Steelskull__Lumosia-MoE-4x10.7)\n",
            "Hugging Face Dataset for Ai usecase in Steel: [Link](https://huggingface.co/datasets/open-llm-leaderboard-old/details_Steelskull__Umbra-MoE-4x10.7)\n",
            "Hugging Face Dataset for Ai usecase in Steel: [Link](https://huggingface.co/datasets/open-llm-leaderboard-old/details_Steelskull__Aurora_base_test)\n",
            "Kaggle Dataset for Ai usecase in Steel: [Link](https://www.kaggle.com/uciml/faulty-steel-plates)\n",
            "Kaggle Dataset for Ai usecase in Steel: [Link](https://www.kaggle.com/csafrit2/steel-industry-energy-consumption)\n",
            "Kaggle Dataset for Ai usecase in Steel: [Link](https://www.kaggle.com/nimapourmoradi/steel-dataset)\n",
            "Kaggle Dataset for Ai usecase in Steel: [Link](https://www.kaggle.com/sureshmecad/steel-plates-faults)\n",
            "Kaggle Dataset for Ai usecase in Steel: [Link](https://www.kaggle.com/fuarresvij/steel-test-data)\n"
          ]
        }
      ]
    }
  ]
}